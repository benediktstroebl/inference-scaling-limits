# Repository to preprint: Inference Scaling FLaws

This repository contains the accompanying code to the preprint with the title **Inference Scaling FLaws**.

The experiments run for this work build on the following publications and their accompanying code repositories.

**EvalPlus ---**
[Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation](https://proceedings.neurips.cc/paper_files/paper/2023/hash/43e9d647ccd3e4b7b5baab53f0368686-Abstract-Conference.html) ([GitHub](https://github.com/evalplus/evalplus)) ([license](https://github.com/evalplus/evalplus/edit/master/LICENSE))

**RACE ---**
[Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models](https://arxiv.org/abs/2407.11470) ([GitHub](https://github.com/jszheng21/RACE)) ([license](https://github.com/jszheng21/RACE?tab=Apache-2.0-1-ov-file))

## General notes

### Structure

- Section 3: The code samples and visualizations can be found in `evalplus/humaneval`, `evalplus/mbpp`, and `evalplus/visualizations.ipynb`
- Section 4: Inference scaling curves are in `evalplus/scaling_curves.ipynb`
- Section 5: Samples and figures on our code quality experiments are in `race/`

## Additional questions and details

You can refer to the paper and its associated appendices for more details on our setup. You can contact us at stroebl@princeton.edu